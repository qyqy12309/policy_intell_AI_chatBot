# Ollama Configuration
OLLAMA_MODEL=llama3  # Options: llama3, mistral, llama2, etc.
# Make sure Ollama is running: ollama serve
# Make sure model is downloaded: ollama pull llama3

# Vector Database Configuration
CHROMA_DB_PATH=./chroma_db

# Application Settings
MAX_CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RESULTS=5

# Server Configuration
HOST=0.0.0.0
PORT=8000

